{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8Y137U8jaot+nqKmcXslg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OrgadShlishman/TAU-DLinMedicalImaging/blob/main/DatasetTools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and import auxilary libraries and packages"
      ],
      "metadata": {
        "id": "GNYKEHNScr6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports and installations\n",
        "!pip install gdown\n",
        "!pip install fastdup -Uq\n",
        "\n",
        "import gdown\n",
        "import os\n",
        "import shutil\n",
        "import fastdup\n",
        "import cv2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from skimage import io, img_as_float, img_as_ubyte, filters\n",
        "\n",
        "fastdup.__version__"
      ],
      "metadata": {
        "id": "ZOoG3OggySBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download your dataset (RAVIR usage example)"
      ],
      "metadata": {
        "id": "Wv3ydQdbc51A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading RAVIR dataset\n",
        "\n",
        "file_id = '1ZlZoSStvE9VCRq3bJiGhQH931EF0h3hh'\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "\n",
        "output = 'ravir-dataset.zip'\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "!unzip ravir-dataset.zip"
      ],
      "metadata": {
        "id": "-ldqvd0wyU8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sharpen Images"
      ],
      "metadata": {
        "id": "MCajpEhXeu-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# My innovative feature\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, img_as_float, img_as_ubyte, filters\n",
        "\n",
        "class ImproveImage:\n",
        "    def __init__(self, input_image_path, output_dir=None, power=15):\n",
        "        \"\"\"\n",
        "        Initialize the ImproveImage class.\n",
        "\n",
        "        Parameters:\n",
        "        - input_image_path: str or list of str, path(s) to the image(s).\n",
        "        - output_dir: str, optional, directory where images will be saved.\n",
        "        \"\"\"\n",
        "        self.output_dir = output_dir\n",
        "        self.power = power\n",
        "\n",
        "        if isinstance(input_image_path, str):\n",
        "            # Single image path\n",
        "            self.input_image_paths = [input_image_path]\n",
        "            self.images = [self.get_img(input_image_path)]\n",
        "            self.sharp_images = [self.sharpen(self.images[0])]\n",
        "        elif isinstance(input_image_path, list):\n",
        "            # List of image paths\n",
        "            self.input_image_paths = input_image_path\n",
        "            self.images = [self.get_img(img_p) for img_p in input_image_path]\n",
        "            self.sharp_images = [self.sharpen(img) for img in self.images]\n",
        "        else:\n",
        "            raise ValueError(\"input_image_path must be a string or a list of strings.\")\n",
        "\n",
        "    def get_img(self, image_path):\n",
        "        \"\"\"\n",
        "        Load and preprocess the image.\n",
        "\n",
        "        Parameters:\n",
        "        - image_path: str, path to the image file.\n",
        "\n",
        "        Returns:\n",
        "        - numpy array, preprocessed image.\n",
        "        \"\"\"\n",
        "        image = io.imread(image_path, as_gray=True)\n",
        "        image = img_as_float(image)\n",
        "        return image\n",
        "\n",
        "    def sharpen(self, image):\n",
        "        \"\"\"\n",
        "        Apply sharpening to the image.\n",
        "\n",
        "        Parameters:\n",
        "        - image: numpy array, input image.\n",
        "\n",
        "        Returns:\n",
        "        - numpy array, sharpened image.\n",
        "        \"\"\"\n",
        "        power = self.power\n",
        "        sharpened_image = filters.unsharp_mask(image, radius=1, amount=power)\n",
        "        return sharpened_image\n",
        "\n",
        "\n",
        "    def preview(self):\n",
        "        \"\"\"\n",
        "        Preview the original and sharpened images.\n",
        "        \"\"\"\n",
        "        for idx, (image, sharp_image) in enumerate(zip(self.images, self.sharp_images)):\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.title(f\"Original Image {idx+1}\")\n",
        "            plt.imshow(image, cmap='gray')\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.title(f\"Sharpened Image {idx+1}\")\n",
        "            plt.imshow(sharp_image, cmap='gray')\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\"\n",
        "        Save the sharpened images to the specified directory.\n",
        "        \"\"\"\n",
        "        if not self.output_dir:\n",
        "            raise ValueError(\"Output directory is not specified.\")\n",
        "\n",
        "        if not os.path.exists(self.output_dir):\n",
        "            os.makedirs(self.output_dir)\n",
        "\n",
        "        for image, input_path in zip(self.sharp_images, self.input_image_paths):\n",
        "            file_name = os.path.basename(input_path)\n",
        "            output_path = os.path.join(self.output_dir, file_name)\n",
        "            io.imsave(output_path, img_as_ubyte(image))\n",
        "            print(f\"Sharpened image saved to: {output_path}\")"
      ],
      "metadata": {
        "id": "jCNFbYsM14rZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usage example: Sharpen and display images"
      ],
      "metadata": {
        "id": "iVKYobeQe1RH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_images\n",
        "train_images\n",
        "\n",
        "print(test_images)\n",
        "print(train_images)"
      ],
      "metadata": {
        "id": "b7lBULls2MR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "output_dir = '/content/RAVIR Dataset/test'\n",
        "sample_img = test_images\n",
        "\n",
        "power=15\n",
        "improve_image_single = ImproveImage(sample_img, output_dir, power)\n",
        "improve_image_single.preview()\n",
        "improve_image_single.save()\n",
        "\n",
        "output_dir = '/content/RAVIR Dataset/train/training_images'\n",
        "sample_img = train_images\n",
        "\n",
        "power=15\n",
        "improve_image_single = ImproveImage(sample_img, output_dir, power)\n",
        "improve_image_single.preview()\n",
        "improve_image_single.save()"
      ],
      "metadata": {
        "id": "szQiXXvi2GYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing Folder"
      ],
      "metadata": {
        "id": "_CpxOQBGdxPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usage example"
      ],
      "metadata": {
        "id": "k73QLvDXf390"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the folder you want to delete\n",
        "folder_to_delete = '/content/MyDrive/MyDrive/Deep Learning/Project/DataSet/3_RAVIR Dataset/test'\n",
        "\n",
        "# Check if the folder exists\n",
        "if os.path.exists(folder_to_delete):\n",
        "    # Delete the folder and all its contents\n",
        "    shutil.rmtree(folder_to_delete)\n",
        "    print(f\"Folder {folder_to_delete} has been deleted.\")\n",
        "else:\n",
        "    print(f\"Folder {folder_to_delete} does not exist.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FirosSWc62Y8",
        "outputId": "f1d345d9-f997-4c81-ce87-5b97aaa73d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder /content/MyDrive/MyDrive/Deep Learning/Project/DataSet/3_RAVIR Dataset/test has been deleted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Copying Folder content"
      ],
      "metadata": {
        "id": "1itRdthUd7dF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usage example"
      ],
      "metadata": {
        "id": "7EWtn2mNf0D1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Define source and destination paths\n",
        "source_folder = '/content/MyDrive/MyDrive/Deep Learning/Project/DataSet/RAVIR Dataset/test'\n",
        "destination_folder = '/content/MyDrive/MyDrive/Deep Learning/Project/DataSet/3_RAVIR Dataset/test'\n",
        "\n",
        "# Ensure the destination folder is empty (or create it if it does not exist)\n",
        "if os.path.exists(destination_folder):\n",
        "    # Optionally, clear the destination folder if it contains files (use with caution)\n",
        "    shutil.rmtree(destination_folder)\n",
        "    os.makedirs(destination_folder)\n",
        "else:\n",
        "    os.makedirs(destination_folder)\n",
        "\n",
        "# Copy the entire folder\n",
        "shutil.copytree(source_folder, destination_folder, dirs_exist_ok=True)\n",
        "print(f\"Folder {source_folder} has been copied to {destination_folder}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS-784916cPQ",
        "outputId": "b57326d3-f2dd-4b3a-eb84-5e0d3fe27ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder /content/MyDrive/MyDrive/Deep Learning/Project/DataSet/RAVIR Dataset/test has been copied to /content/MyDrive/MyDrive/Deep Learning/Project/DataSet/3_RAVIR Dataset/test.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation Generation"
      ],
      "metadata": {
        "id": "gvdUkE3lv9oZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def augment_and_save_images(image_dir, mask_dir, output_image_dir, output_mask_dir, num_augments=24):\n",
        "    # Define a set of augmentations\n",
        "    transform = A.Compose([\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "        A.Rotate(limit=40, p=0.5),\n",
        "        A.RandomBrightnessContrast(p=0.2),\n",
        "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=20, p=0.5),\n",
        "        A.GaussianBlur(p=0.3),\n",
        "        A.RandomGamma(p=0.2),\n",
        "        A.ElasticTransform(p=0.2),\n",
        "        A.GridDistortion(p=0.2),\n",
        "        A.CoarseDropout(max_holes=8, max_height=16, max_width=16, p=0.5),\n",
        "        A.Normalize(mean=(0.5,), std=(0.5,)),\n",
        "        ToTensorV2()\n",
        "    ])\n",
        "\n",
        "    # Ensure output directories exist\n",
        "    os.makedirs(output_image_dir, exist_ok=True)\n",
        "    os.makedirs(output_mask_dir, exist_ok=True)\n",
        "\n",
        "    # List all image files\n",
        "    image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
        "\n",
        "    for image_name in image_files:\n",
        "        image_path = os.path.join(image_dir, image_name)\n",
        "        mask_name = image_name  # Assuming mask has the same name as the image\n",
        "        mask_path = os.path.join(mask_dir, mask_name)\n",
        "\n",
        "        # Read image and mask\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Generate augmented images and masks\n",
        "        for i in range(num_augments):\n",
        "            augmented = transform(image=image, mask=mask)\n",
        "            augmented_image = augmented['image'].numpy().transpose(1, 2, 0)  # Convert to numpy array\n",
        "            augmented_mask = augmented['mask'].numpy().squeeze()  # Convert to numpy array\n",
        "\n",
        "            # Convert from normalized [-1, 1] back to [0, 255] if needed\n",
        "            augmented_image = ((augmented_image * 0.5 + 0.5) * 255).astype(np.uint8)\n",
        "            augmented_mask = (augmented_mask * 255).astype(np.uint8)\n",
        "\n",
        "            # Save the augmented image and mask\n",
        "            aug_image_name = f\"{os.path.splitext(image_name)[0]}_aug_{i+1}.png\"\n",
        "            aug_mask_name = f\"{os.path.splitext(mask_name)[0]}_aug_{i+1}.png\"\n",
        "\n",
        "            cv2.imwrite(os.path.join(output_image_dir, aug_image_name), cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR))\n",
        "            cv2.imwrite(os.path.join(output_mask_dir, aug_mask_name), augmented_mask)\n",
        "\n",
        "    print(f\"Augmentation complete. Augmented images and masks saved to '{output_image_dir}' and '{output_mask_dir}' respectively.\")\n"
      ],
      "metadata": {
        "id": "zQvz96_Kv8Yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optional: Use Google Drive for your input\\output folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00qphIYgwHlh",
        "outputId": "02c25385-7c5b-42da-c10d-a0150d009004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usage example"
      ],
      "metadata": {
        "id": "OmoWn0nLfq69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = '/content/drive/MyDrive/Deep Learning/Project/DataSet/RAVIR Dataset Aug2/train/images'\n",
        "mask_dir = '/content/drive/MyDrive/Deep Learning/Project/DataSet/RAVIR Dataset Aug2/train/mask'\n",
        "\n",
        "output_image_dir = '/content/drive/MyDrive/Deep Learning/Project/DataSet/Aug Dataset/train/images'\n",
        "output_mask_dir = '/content/drive/MyDrive/Deep Learning/Project/DataSet/Aug Dataset/train/mask'\n",
        "\n",
        "output_image_dir = '/content/drive/MyDrive/Deep Learning/Project/DataSet/RAVIR Dataset Aug2/train/images'\n",
        "output_mask_dir = '/content/drive/MyDrive/Deep Learning/Project/DataSet/RAVIR Dataset Aug2/train/mask'\n",
        "\n",
        "\n",
        "augment_and_save_images(image_dir, mask_dir, output_image_dir, output_mask_dir, num_augments=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N34COUI2wCtR",
        "outputId": "f23cf48c-a2b6-403a-b4fa-12a465cccc55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Augmentation complete. Augmented images and masks saved to '/content/drive/MyDrive/Deep Learning/Project/DataSet/RAVIR Dataset Aug2/train/images' and '/content/drive/MyDrive/Deep Learning/Project/DataSet/RAVIR Dataset Aug2/train/mask' respectively.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backups"
      ],
      "metadata": {
        "id": "NOQ4U0a5dGP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define paths\n",
        "source_images_path = '/content/RAVIR Dataset/train/training_images'\n",
        "source_masks_path = '/content/RAVIR Dataset/train/training_masks'\n",
        "\n",
        "destination_images_path = source_images_path\n",
        "destination_masks_path = source_masks_path\n",
        "\n",
        "\n",
        "source_images_path = '/content/RAVIR Dataset/test'\n",
        "destination_images_path = source_images_path\n",
        "\n",
        "\n",
        "# Ensure destination folders exist\n",
        "os.makedirs(destination_images_path, exist_ok=True)\n",
        "os.makedirs(destination_masks_path, exist_ok=True)\n",
        "\n",
        "# List of existing files\n",
        "image_files = [f for f in os.listdir(source_images_path) if f.endswith('.png')]  # Adjust extension if needed\n",
        "mask_files = [f for f in os.listdir(source_masks_path) if f.endswith('.png')]  # Adjust extension if needed\n",
        "\n",
        "# Extract the number part from filenames and sort them\n",
        "def extract_number(filename):\n",
        "    try:\n",
        "        # Assuming filenames are in the format 'IR_Case_X.png'\n",
        "        return int(filename.split('_')[2].split('.')[0])\n",
        "    except (IndexError, ValueError):\n",
        "        raise ValueError(f\"Filename format is incorrect: {filename}\")\n",
        "\n",
        "image_files = sorted(image_files, key=extract_number)\n",
        "mask_files = sorted(mask_files, key=extract_number)\n",
        "\n",
        "# Define a starting number for the new names\n",
        "new_start_number = 84\n",
        "\n",
        "# Copy and rename files\n",
        "# for i, (image_file, mask_file) in enumerate(zip(image_files, mask_files), start=new_start_number):\n",
        "for i, (image_file) in enumerate(zip(image_files), start=new_start_number):\n",
        "    # Define new filenames\n",
        "    new_image_filename = f'IR_Case_{i}.png'\n",
        "    # new_mask_filename = f'IR_Case_{i}.png'\n",
        "\n",
        "    # Define source and destination paths\n",
        "    src_image_path = os.path.join(source_images_path, image_file)\n",
        "    dst_image_path = os.path.join(destination_images_path, new_image_filename)\n",
        "    # src_mask_path = os.path.join(source_masks_path, mask_file)\n",
        "    # dst_mask_path = os.path.join(destination_masks_path, new_mask_filename)\n",
        "\n",
        "    # Copy and rename files\n",
        "    shutil.copy(src_image_path, dst_image_path)\n",
        "    # shutil.copy(src_mask_path, dst_mask_path)\n",
        "\n",
        "print(\"Files have been copied and renamed successfully.\")\n"
      ],
      "metadata": {
        "id": "oGxUM72ZzjjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define paths\n",
        "source_images_path = '/content/RAVIR Dataset/test'\n",
        "destination_images_path = source_images_path\n",
        "\n",
        "# Ensure destination folder exists\n",
        "os.makedirs(destination_images_path, exist_ok=True)\n",
        "\n",
        "# List of existing files\n",
        "image_files = [f for f in os.listdir(source_images_path) if f.endswith('.png')]  # Adjust extension if needed\n",
        "\n",
        "# Extract the number part from filenames and sort them\n",
        "def extract_number(filename):\n",
        "    try:\n",
        "        # Assuming filenames are in the format 'IR_Case_X.png'\n",
        "        return int(filename.split('_')[2].split('.')[0])\n",
        "    except (IndexError, ValueError):\n",
        "        raise ValueError(f\"Filename format is incorrect: {filename}\")\n",
        "\n",
        "image_files = sorted(image_files, key=extract_number)\n",
        "\n",
        "# Define a starting number for the new names\n",
        "new_start_number = 84\n",
        "\n",
        "# Copy and rename files\n",
        "for i, image_file in enumerate(image_files, start=new_start_number):\n",
        "    # Ensure the filename is a string\n",
        "    if not isinstance(image_file, str):\n",
        "        raise TypeError(f\"Expected str, but got {type(image_file).__name__}\")\n",
        "\n",
        "    # Define new filename\n",
        "    new_image_filename = f'IR_Case_{i}.png'\n",
        "\n",
        "    # Define source and destination paths\n",
        "    src_image_path = os.path.join(source_images_path, image_file)\n",
        "    dst_image_path = os.path.join(destination_images_path, new_image_filename)\n",
        "\n",
        "    # Copy and rename files\n",
        "    shutil.copy(src_image_path, dst_image_path)\n",
        "\n",
        "print(\"Files have been copied and renamed successfully.\")\n"
      ],
      "metadata": {
        "id": "gSU-CNhM0suv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "# Define the path to the folder\n",
        "folder_path = '/content/RAVIR Dataset/train/training_images'\n",
        "\n",
        "# List all files in the folder\n",
        "files = os.listdir(folder_path)\n",
        "\n",
        "# Define a pattern to extract numbers from filenames\n",
        "pattern = re.compile(r'(\\d+)\\.png$')  # Adjust the regex if your files have a different extension\n",
        "\n",
        "# Initialize a list to store full paths\n",
        "filtered_paths = []\n",
        "\n",
        "# Iterate over each file in the folder\n",
        "for file in files:\n",
        "    # Search for a number in the filename using regex\n",
        "    match = pattern.search(file)\n",
        "\n",
        "    if match:\n",
        "        number = int(match.group(1))  # Extract the number and convert to integer\n",
        "\n",
        "        # Check if the number is less than 84\n",
        "        if number < 84:\n",
        "            # Generate the full path and add to the list\n",
        "            full_path = os.path.join(folder_path, file)\n",
        "            filtered_paths.append(full_path)\n",
        "\n",
        "# The variable `filtered_paths` now contains the list of image paths\n",
        "print(filtered_paths)  # This will print the list of paths for verification\n",
        "\n",
        "# If you need to use `filtered_paths` further, it’s already available in this variable\n",
        "\n",
        "test_images = filtered_paths\n",
        "# print(train_images)\n",
        "# print(type(train_images))"
      ],
      "metadata": {
        "id": "C9c4xEV21Npu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "# Define the path to the folder\n",
        "folder_path = '/content/RAVIR Dataset/train/training_images'\n",
        "\n",
        "# List all files in the folder\n",
        "files = os.listdir(folder_path)\n",
        "\n",
        "# Define a pattern to extract numbers from filenames\n",
        "pattern = re.compile(r'(\\d+)\\.png$')  # Adjust the regex if your files have a different extension\n",
        "\n",
        "# Initialize a list to store full paths\n",
        "filtered_paths = []\n",
        "\n",
        "# Iterate over each file in the folder\n",
        "for file in files:\n",
        "    # Search for a number in the filename using regex\n",
        "    match = pattern.search(file)\n",
        "\n",
        "    if match:\n",
        "        number = int(match.group(1))  # Extract the number and convert to integer\n",
        "\n",
        "        # Check if the number is less than 84\n",
        "        if number < 60:\n",
        "            # Generate the full path and add to the list\n",
        "            full_path = os.path.join(folder_path, file)\n",
        "            filtered_paths.append(full_path)\n",
        "\n",
        "# The variable `filtered_paths` now contains the list of image paths\n",
        "print(filtered_paths)  # This will print the list of paths for verification\n",
        "\n",
        "# If you need to use `filtered_paths` further, it’s already available in this variable\n",
        "\n",
        "train_images = filtered_paths\n",
        "# print(train_images)\n",
        "# print(type(train_images))"
      ],
      "metadata": {
        "id": "Zgmc9Yla1h-7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}